{"id":"hi_moe-00z","title":"Reduce hierarchy latency vs baseline (218s -\u003e closer to 64s)","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T07:55:24.466992-08:00","updated_at":"2025-12-27T08:04:33.812625-08:00","closed_at":"2025-12-27T08:04:33.812625-08:00","close_reason":"Implemented tier-skip fast path for simple problems. For simple coding tasks (function_name + function_signature defined, \u003c1000 chars, no multi-step indicators), Runner now skips Architect/Dispatcher and calls Fleet directly. Reduces LLM calls from 4-5 to 1, expected latency improvement from ~218s to ~50s for simple problems. Parallelization deferred as it only helps complex multi-step problems.","dependencies":[{"issue_id":"hi_moe-00z","depends_on_id":"hi_moe-1e7","type":"blocks","created_at":"2025-12-27T07:55:33.325723-08:00","created_by":"daemon"}]}
{"id":"hi_moe-0n5","title":"Continuous learning / manifold surface","description":"System should move smoothly through representational space rather than discrete jumps. Smooth state transitions, incremental updates.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-23T13:21:31.647017-07:00","updated_at":"2025-12-27T10:27:13.196616-08:00","closed_at":"2025-12-27T10:27:13.196616-08:00","close_reason":"Implemented continuous learning with EMA-based smooth transitions and incremental updates"}
{"id":"hi_moe-0qv","title":"Baseline comparison: single model vs hierarchy","description":"Measure coordination value vs capability: Need baseline using single model with no hierarchy to prove the complexity pays for itself. Run same problem set through both, compare success rate and efficiency.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-27T05:57:23.857711-08:00","closed_at":"2025-12-27T05:57:23.857711-08:00","close_reason":"Comparison complete: Both baseline (single model) and hierarchy achieve 100% pass rate. Baseline is 3.4x faster (64s vs 218s avg) for simple problems. Hierarchy overhead (4-5 LLM calls) not justified for easy tasks. Tool created: run_baseline_comparison.py","dependencies":[{"issue_id":"hi_moe-0qv","depends_on_id":"hi_moe-ld8","type":"blocks","created_at":"2025-12-26T03:10:27.800072Z","created_by":"claude"}]}
{"id":"hi_moe-1e7","title":"Evaluate H100 GPU for inference speedup","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T07:55:24.688648-08:00","updated_at":"2025-12-27T09:50:25.235008-08:00","closed_at":"2025-12-27T09:50:25.235008-08:00","close_reason":"Added H100 GPU Evaluation section to modal_deployment.md with baseline, expected improvements, and decision criteria"}
{"id":"hi_moe-1ke","title":"Valence signals (feelings) for decisions","description":"Implement simple good/bad scalar attached to outcomes. Provides gradient for the system to follow - 'that worked, do more of that.' Informs routing decisions and routine caching.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:20:34.630229-07:00","updated_at":"2025-12-23T19:28:13.24811-07:00","closed_at":"2025-12-23T19:28:13.24811-07:00","dependencies":[{"issue_id":"hi_moe-1ke","depends_on_id":"hi_moe-5o2","type":"blocks","created_at":"2025-12-23T13:23:27.45638-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-2tx","title":"State continuity (context vector evolution)","description":"Beads state object maintains compressed 'context vector' that evolves smoothly across tasks rather than resetting. Gives system sense of trajectory.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:21:51.633233-07:00","updated_at":"2025-12-27T10:30:58.636616-08:00","closed_at":"2025-12-27T10:30:58.636616-08:00","close_reason":"Implemented StateEvolver with EMA-based context evolution in advanced_coordination.py","dependencies":[{"issue_id":"hi_moe-2tx","depends_on_id":"hi_moe-0n5","type":"blocks","created_at":"2025-12-23T13:24:09.017515-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-2ze","title":"DAG support for parallel task execution","description":"Deferred post-v0.1: Support task dependency graphs with parallel execution branches. Requires: parallel specialist invocation, dependency resolution, result aggregation from branches. Blocked by proving linear sequence works first.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-26T03:18:20.660493Z","updated_at":"2025-12-27T10:30:59.904192-08:00","closed_at":"2025-12-27T10:30:59.904192-08:00","close_reason":"Implemented DAGExecutor with parallel branch execution in advanced_coordination.py","dependencies":[{"issue_id":"hi_moe-2ze","depends_on_id":"hi_moe-d87","type":"blocks","created_at":"2025-12-26T03:18:49.158216Z","created_by":"claude"}]}
{"id":"hi_moe-3ie","title":"Novelty-weighted memory \u0026 forgetting","description":"Implement attention allocation via novelty weighting. Events within confidence bounds get exponentially decayed. Surprises retained longer. Forgetting routine events is a feature.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:20:40.911195-07:00","updated_at":"2025-12-23T19:28:13.248941-07:00","closed_at":"2025-12-23T19:28:13.248941-07:00","dependencies":[{"issue_id":"hi_moe-3ie","depends_on_id":"hi_moe-5o2","type":"blocks","created_at":"2025-12-23T13:23:32.89293-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-3ml","title":"Self-reflection \u0026 architecture visibility","description":"Enable the system to model itself. Allow introspection into its own capabilities, bottlenecks, and state.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-23T13:20:57.830897-07:00","updated_at":"2025-12-27T09:53:51.185055-08:00","closed_at":"2025-12-27T09:53:51.185055-08:00","close_reason":"Implemented self_reflection.py with architecture introspection, bottleneck detection, capability gaps, and self-description"}
{"id":"hi_moe-3oq","title":"Abstract Architect tier implementation","description":"First tier of hierarchy - sets strategic goals. Uses frozen Qwen QwQ-32B base. Communicates through structured handoffs: delegating down, receiving outcomes up.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-23T13:22:15.938819-07:00","updated_at":"2025-12-23T14:43:39.689623-07:00","closed_at":"2025-12-23T14:43:39.689623-07:00"}
{"id":"hi_moe-3qj","title":"Code execution sandbox (CodeRunner)","description":"Fleet generates code but needs to actually execute/test it. Implement CodeRunner component with Docker isolation for safe code execution. Required for competitive programming validation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T14:16:27.312876-07:00","updated_at":"2025-12-23T14:53:40.168529-07:00","closed_at":"2025-12-23T14:53:40.168529-07:00"}
{"id":"hi_moe-46g","title":"LoRA strategy: train only when proven necessary","description":"Revised strategy: skip LoRAs entirely for v0.1. Benefits: validate coordination architecture first, skip training/loading complexity, defer S-LoRA integration, faster iteration. Decision: train or download LoRAs only when evidence shows base model is not good enough for a specific tier. Check HuggingFace for existing Qwen/QwQ adapters (but adapters are model-specific).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:37:53.239233Z","updated_at":"2025-12-27T09:50:25.184989-08:00","closed_at":"2025-12-27T09:50:25.184989-08:00","close_reason":"Added LoRA Deferral Strategy section to lora_infrastructure.md with rationale and evaluation protocol","dependencies":[{"issue_id":"hi_moe-46g","depends_on_id":"hi_moe-rj4","type":"blocks","created_at":"2025-12-26T03:38:12.826153Z","created_by":"claude"}]}
{"id":"hi_moe-4dy","title":"Dispatcher structured output via prompt enforcement","description":"Minimal schema: {\"steps\": [{\"description\": \"string\", \"specialist\": \"python|math|general\"}]}. Enforce via prompt engineering + validation + single retry. QwQ should achieve ~90%+ parse success. Defer vLLM guided generation until parsing failures become a real problem.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:18:20.660493Z","updated_at":"2025-12-26T03:58:29.763179Z","closed_at":"2025-12-26T03:58:29.763156Z"}
{"id":"hi_moe-4nv","title":"Session retrospective: tier system improvements","description":"","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-26T16:41:42.415093-08:00","updated_at":"2025-12-26T16:41:57.447546-08:00","closed_at":"2025-12-26T16:41:57.447546-08:00","close_reason":"## Session Summary (Dec 26, 2024)\n\n### Completed Issues\n- hi_moe-f5d: Self-healing with code validation retry\n- hi_moe-ceg: Multi-turn context to tier system\n\n### Code Review Notes\n1. **Self-healing (f5d)**\n   - Clean integration: validation happens after code extraction in _execute_once\n   - Error feedback is detailed: shows expected vs actual, runtime errors\n   - Feeds into existing Fleet retry mechanism\n   \n2. **Multi-turn context (ceg)**\n   - SpecialistStats uses simple success rate - works but could add recency weighting later\n   - get_relevant_solutions uses keyword overlap - basic but functional, embeddings could improve\n   - Dispatcher preference logic preserves keyword-matched specialists first, then reorders by history\n   \n### Technical Debt / Future Work\n- datetime.utcnow() deprecation warnings throughout - should migrate to datetime.now(datetime.UTC)\n- ConversationContext could persist to disk/Redis for longer sessions\n- Solution similarity could use embeddings instead of keyword overlap\n\n### Test Status\n- 114 tests passing\n- Added 14 new tests (7 self-healing + 7 multi-turn)"}
{"id":"hi_moe-5ip","title":"Tool usage tracking \u0026 analytics","description":"Track usage of all tools - what's used vs unused. Use analytics to inform future tool construction. Problems can identify missing tools.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:22:08.957477-07:00","updated_at":"2025-12-27T09:53:51.134177-08:00","closed_at":"2025-12-27T09:53:51.134177-08:00","close_reason":"Implemented tool_analytics.py with invocation tracking, usage patterns, missing tool signals, and analytics reports"}
{"id":"hi_moe-5o2","title":"Progress Monitor (Fourth Tier)","description":"Create a meta-layer above Abstract Architect that tracks whether the system is making progress, not just planning/executing. Home for progress tracking, surprise detection, and valence signals.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-23T13:20:21.527607-07:00","updated_at":"2025-12-23T19:25:51.02528-07:00","closed_at":"2025-12-23T19:25:51.02528-07:00","dependencies":[{"issue_id":"hi_moe-5o2","depends_on_id":"hi_moe-3oq","type":"blocks","created_at":"2025-12-23T13:24:15.743374-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-6ik","title":"Add code execution sandbox for validation","description":"Integrate a sandboxed code execution environment (e.g., Modal sandbox or RestrictedPython) to validate generated code against test cases before returning results.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T15:37:08.741438-08:00","updated_at":"2025-12-26T16:28:31.612359-08:00","closed_at":"2025-12-26T16:28:31.612359-08:00","close_reason":"Implemented CodeRunner with subprocess sandbox, timeout handling, 17 tests"}
{"id":"hi_moe-6x1","title":"Define BeadsClient interface","description":"Specs reference BeadsClient but interface is undefined. Define the client API for get/set/append operations, or document how to use existing beads CLI from Python.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T14:16:33.994591-07:00","updated_at":"2025-12-23T19:14:14.136763-07:00","closed_at":"2025-12-23T19:14:14.136763-07:00"}
{"id":"hi_moe-756","title":"Model selection optimization per tier","description":"Deferred optimization: QwQ reasoning overhead is helpful for Architect (strategy) and Dispatcher (routing analysis) but wasteful for Fleet (just execute). Consider Qwen2.5-Instruct for Fleet as faster alternative. v0.1: use QwQ everywhere for simplicity, optimize later if reasoning overhead becomes a bottleneck.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-26T03:37:53.239233Z","updated_at":"2025-12-26T03:38:12.826153Z","dependencies":[{"issue_id":"hi_moe-756","depends_on_id":"hi_moe-wvi","type":"blocks","created_at":"2025-12-26T03:38:12.826153Z","created_by":"claude"}]}
{"id":"hi_moe-7af","title":"Fix datetime.utcnow() deprecation warnings","description":"Replace datetime.utcnow() with datetime.now(datetime.UTC) in trajectory_logger.py, tiers.py, and runner.py. Python 3.12+ deprecation.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-26T15:37:21.742785-08:00","updated_at":"2025-12-26T17:01:29.781479-08:00","closed_at":"2025-12-26T17:01:29.781479-08:00","close_reason":"Replaced all 12 datetime.utcnow() calls with datetime.now(timezone.utc) in 4 files: tiers.py (6), trajectory_logger.py (3), runner.py (1), vllm_server.py (2). Warnings reduced from 89 to 2 (remaining are unrelated pytest collection warnings). All 128 tests pass."}
{"id":"hi_moe-7b5","title":"Soft routing (weighted specialist contributions)","description":"Instead of hard routing to single specialist, weight contributions from multiple specialists based on task embedding similarity. Routing LoRA learns soft weights.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:21:38.899476-07:00","updated_at":"2025-12-27T10:30:57.928811-08:00","closed_at":"2025-12-27T10:30:57.928811-08:00","close_reason":"Implemented SoftRouter with weighted specialist routing in advanced_coordination.py","dependencies":[{"issue_id":"hi_moe-7b5","depends_on_id":"hi_moe-0n5","type":"blocks","created_at":"2025-12-23T13:23:58.089804-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-836","title":"Test trained python-test adapter against eval benchmarks","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T15:36:49.048581-08:00","updated_at":"2025-12-26T18:48:21.345148-08:00","closed_at":"2025-12-26T18:48:21.345148-08:00","close_reason":"Tested python-lora adapter against base model on python_eval.jsonl (5 samples). Results: Both achieved 100% success rate. Base model: 80% code gen, 40s avg response. Adapter: 60% code gen, 82s avg response. Adapter performs slightly slower (expected due to LoRA overhead with minimal training). Fixed missing volume mount in evaluate.py to enable the comparison. Eval infrastructure fully functional."}
{"id":"hi_moe-881","title":"Strategy versioning \u0026 routine saving","description":"When system discovers successful approach to a problem class, snapshot that routing pattern + LoRA combination as named 'routine'. Retrieve and replay on similar problems.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:21:10.860445-07:00","updated_at":"2025-12-27T09:56:06.796982-08:00","closed_at":"2025-12-27T09:56:06.796982-08:00","close_reason":"Implemented Routine class with pattern capture, versioning, and reliability tracking","dependencies":[{"issue_id":"hi_moe-881","depends_on_id":"hi_moe-3ml","type":"blocks","created_at":"2025-12-23T13:23:45.729618-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-8ig","title":"vLLM guided generation for structured output","description":"Deferred: Use vLLM JSON schema enforcement for dispatcher output instead of prompt-based enforcement. Add only if prompt-based parsing failures exceed ~10%.","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-26T03:18:20.660493Z","updated_at":"2025-12-26T03:18:49.158216Z","dependencies":[{"issue_id":"hi_moe-8ig","depends_on_id":"hi_moe-4dy","type":"blocks","created_at":"2025-12-26T03:18:49.158216Z","created_by":"claude"}]}
{"id":"hi_moe-9km","title":"Mode collapse prevention in specialist training","description":"From Gemini feedback: Include handoff protocol examples in training data to prevent mode collapse during specialist LoRA training. Data quality matters more than training technique.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-27T09:42:20.551081-08:00","closed_at":"2025-12-27T09:42:20.551081-08:00","close_reason":"Implemented handoff_training_data.py with balanced accept/escalate examples for all specialists, tier boundary respect, and context preservation patterns"}
{"id":"hi_moe-9wm","title":"Implement surprise detector for Progress Monitor","description":"","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-23T20:32:42.632007-07:00","updated_at":"2025-12-23T20:32:42.632007-07:00"}
{"id":"hi_moe-a1p","title":"Routine compression into skills","description":"Abstract successful repeated patterns into higher-level 'skills'. Individual instances can then be dropped. Saves useful routines for later reuse.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:21:17.462915-07:00","updated_at":"2025-12-27T09:56:06.848963-08:00","closed_at":"2025-12-27T09:56:06.848963-08:00","close_reason":"Implemented Skill class with compression from routines, trigger keywords, and problem class inference","dependencies":[{"issue_id":"hi_moe-a1p","depends_on_id":"hi_moe-3ml","type":"blocks","created_at":"2025-12-23T13:23:51.152722-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-a4w","title":"Tiered retry logic with escalation","description":"Implement retry logic per tier: Fleet (2-3 retries, same specialist with error context), Dispatcher (1-2 retries, try different specialist), Architect (1 retry, revise plan with failure summary), Top-level (1 retry, give up and log everything). Termination: success/max retries/explicit give up.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-26T16:11:14.472993-08:00","closed_at":"2025-12-26T16:11:14.472993-08:00","close_reason":"Implemented tiered retry: Fleet (2), Dispatcher (1, different specialist), Architect (1, revised plan), Monitor (1, give up)"}
{"id":"hi_moe-bfi","title":"S-LoRA + vLLM integration for hot-swap","description":"Implement unified paging via S-LoRA and vLLM to enable running 12+ specialists concurrently without latency spikes. Solves the hot-swap problem.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T13:22:53.363402-07:00","updated_at":"2025-12-23T13:45:03.375705-07:00","closed_at":"2025-12-23T13:45:03.375705-07:00"}
{"id":"hi_moe-bh3","title":"Improve tier routing logic with learned router","description":"","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T15:36:52.921802-08:00","updated_at":"2025-12-27T09:40:18.294243-08:00","closed_at":"2025-12-27T09:40:18.294243-08:00","close_reason":"Implemented learned_router.py with online learning, feature extraction, per-specialist models, and integrated into RoutingDispatcher"}
{"id":"hi_moe-ceg","title":"Add multi-turn context to tier system","description":"Allow tasks to maintain context across multiple turns. The architect could remember previous solutions and dispatcher could track specialist performance over time.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T15:37:19.92681-08:00","updated_at":"2025-12-26T16:39:53.714912-08:00","closed_at":"2025-12-26T16:39:53.714912-08:00","close_reason":"Implemented multi-turn context for specialist preference and solution history"}
{"id":"hi_moe-cg2","title":"Harness learning loop (meta-learning)","description":"Decision: Is this a fixed orchestration system, or one that learns/adapts coordination strategies? If adaptive, Progress Monitor provides training signal for harness itself.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-23T13:23:00.182416-07:00","updated_at":"2025-12-27T10:27:13.145103-08:00","closed_at":"2025-12-27T10:27:13.145103-08:00","close_reason":"Implemented MetaLearner in meta_learning.py with strategy adaptation and learning signals"}
{"id":"hi_moe-d2j","title":"Add vector trajectory tracking via embeddings","description":"","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-23T20:32:50.61286-07:00","updated_at":"2025-12-23T20:32:50.61286-07:00"}
{"id":"hi_moe-d87","title":"Linear task sequence execution (v0.1 simplification)","description":"Dispatcher produces ordered list of steps, not a dependency graph. Execute steps sequentially, re-plan only on failure. Defers: parallel execution branches, complex dependency graphs, dynamic graph modification mid-execution.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:18:20.660493Z","updated_at":"2025-12-26T04:03:52.603555Z","closed_at":"2025-12-26T04:03:52.603511Z"}
{"id":"hi_moe-dip","title":"Train algorithms specialist adapter on CodeContests dataset","description":"","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-26T15:36:51.850291-08:00","updated_at":"2025-12-26T15:36:51.850291-08:00"}
{"id":"hi_moe-e8h","title":"Integrate adapter with vLLM inference server","description":"Once training completes, upload the python-test adapter to the hi-moe-adapters volume and configure vLLM to serve it via dynamic LoRA loading.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T15:37:07.511943-08:00","updated_at":"2025-12-26T18:07:14.74881-08:00","closed_at":"2025-12-26T18:07:14.74881-08:00","close_reason":"Fixed training.py to work with TRL 0.9.6 API: pinned TRL version, added rich dep, pre-format dataset for SFTTrainer. Trained python-lora adapter successfully and verified it's registered in vLLM inference server."}
{"id":"hi_moe-f5d","title":"Implement self-healing with retry on code execution failure","description":"When code fails validation, send error feedback to the specialist for correction. Track retry counts and use escalation logic.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T15:37:09.796891-08:00","updated_at":"2025-12-26T16:34:24.104432-08:00","closed_at":"2025-12-26T16:34:24.104432-08:00","close_reason":"Implemented self-healing with code validation retry"}
{"id":"hi_moe-fh2","title":"Tournament for Architect prompt variants","description":"Instead of hand-tuning Architect management style, run competitions: Create 2-3 prompt variants (terse vs detailed, aggressive vs conservative), run same problem set through each, track success rate/token efficiency/time, keep winners. Generates coordination training signal without complex meta-learning.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-27T09:36:36.318149-08:00","closed_at":"2025-12-27T09:36:36.318149-08:00","close_reason":"Implemented architect_tournament.py with 4 prompt variants (terse, detailed, aggressive, conservative), efficiency scoring, and winner selection"}
{"id":"hi_moe-ftb","title":"Add debugging and refactoring specialist adapters","description":"Train LoRA adapters for debugging and refactoring specialists. System prompts already exist in tiers.py. Need training datasets for these domains.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-26T15:37:06.573204-08:00","updated_at":"2025-12-26T15:37:06.573204-08:00"}
{"id":"hi_moe-gdf","title":"Design: Agent context window strategy","description":"Explore context window management approaches for agent LLM calls:\n\n## Options\n\n### 1. Stateless (current)\n- Fresh prompt each vLLM call, no memory\n- Pros: Simple, no state management, easy to parallelize\n- Cons: Agent loses prior reasoning, may repeat mistakes\n\n### 2. Summarize \u0026 cache per-agent\n- After each call, summarize key insights into TaskContext\n- Feed summary back as 'agent memory' on subsequent calls\n- NOT shared across hierarchy (Architect memory ≠ Fleet memory)\n- Pros: Lightweight, agent-private learnings persist\n- Cons: Lossy compression, need good summarization\n\n### 3. Multi-context sessions (persistent KV cache)\n- Keep separate vLLM context windows open per agent\n- Full conversation history within each agent's session\n- Pros: Full fidelity, natural multi-turn reasoning\n- Cons: Memory intensive (4 agents × context), vLLM session management complexity\n\n## Considerations\n- Self-healing loop already benefits from error feedback (option 1 + explicit error context)\n- Architect may benefit from remembering prior plans that failed\n- Fleet specialists are often one-shot (may not need memory)\n- Modal cold starts may complicate persistent sessions","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T05:10:05.927686-08:00","updated_at":"2025-12-27T05:20:00.342734-08:00","closed_at":"2025-12-27T05:20:00.342734-08:00","close_reason":"Implemented Option 2 (summarize \u0026 cache per-agent). Added ArchitectMemory for per-run failed plan tracking. Memory injected into prompts on retries. Tests pass 2/2."}
{"id":"hi_moe-gr7","title":"Math-first vs Python-direct routing decision logging","description":"Let the model decide routing strategy via prompt. Track math-first vs python-direct decisions alongside outcomes. Signals for math-first: optimization, correctness proofs, time complexity tradeoffs, graph theory. Signals for python-direct: implementation-heavy, spec is the algorithm, string manipulation. Free training data for future routing LoRA.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:18:20.660493Z","updated_at":"2025-12-26T16:23:08.237669-08:00","closed_at":"2025-12-26T16:23:08.237669-08:00","close_reason":"Implemented routing strategy detection with math_first vs python_direct logging","dependencies":[{"issue_id":"hi_moe-gr7","depends_on_id":"hi_moe-r8q","type":"blocks","created_at":"2025-12-26T03:18:49.158216Z","created_by":"claude"}]}
{"id":"hi_moe-hzm","title":"Structured handoff protocol between tiers","description":"Define communication protocol: delegating down, reporting outcomes up. Beads keeps abstract tier aware of detailed outcomes - state object all tiers can read.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T13:23:06.839143-07:00","updated_at":"2025-12-23T13:39:50.511681-07:00","closed_at":"2025-12-23T13:39:50.511681-07:00"}
{"id":"hi_moe-ihj","title":"Cloud economics tracking and buy vs rent criteria","description":"Track Modal costs: A100 80GB ~$2.50/hr, estimated ~$100/month for 10hr/week dev. Buy vs rent break-even: ~7,600 hours (~12-18 months heavy use). Hidden costs of buying: electricity, cooling, chassis/CPU/RAM, maintenance, depreciation. Revisit buying if burning $1k+/month consistently.","status":"closed","priority":4,"issue_type":"task","created_at":"2025-12-26T03:37:53.239233Z","updated_at":"2025-12-27T10:27:13.089714-08:00","closed_at":"2025-12-27T10:27:13.089714-08:00","close_reason":"Implemented cloud_economics.py with cost tracking, buy vs rent analysis, and break-even calculations"}
{"id":"hi_moe-irp","title":"Tinybox evaluation: revisit criteria","description":"Document when to revisit tinybox purchase: 1) Architecture proven on Modal, 2) Monthly cloud costs exceed $2-3k, 3) Need dedicated 24/7 training/dev rig. Skip for v0.1 due to: redundant infrastructure, vLLM issues with consumer GPUs without NVLink, S-LoRA less tested on consumer cards.","status":"open","priority":4,"issue_type":"task","created_at":"2025-12-26T03:18:20.660493Z","updated_at":"2025-12-26T03:18:20.660493Z"}
{"id":"hi_moe-iz9","title":"Runner trajectory logging for vLLM calls","description":"Log every vLLM call with: ts, task_id, call_id, tier, specialist, lora, input, output, tokens_in, tokens_out, latency_ms, status. Storage: JSONL append-only, one file per run in runs/ directory. Unlocks: debugging (replay failures), training data (filter successful traces), cost tracking (tokens per task/tier), performance tuning (identify bottlenecks).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:37:53.239233Z","updated_at":"2025-12-26T04:13:53.081206Z","closed_at":"2025-12-26T04:13:53.081206Z","dependencies":[{"issue_id":"hi_moe-iz9","depends_on_id":"hi_moe-xv1","type":"blocks","created_at":"2025-12-26T03:38:12.826153Z","created_by":"claude"}]}
{"id":"hi_moe-jho","title":"Specialized Fleet (LoRA adapters)","description":"Third tier - domain-specific execution via LoRA adapters (Python, CUDA, Math, etc.). All share frozen Qwen QwQ-32B base. Hot-swap via S-LoRA + vLLM unified paging for 12+ concurrent specialists.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-23T13:22:28.514148-07:00","updated_at":"2025-12-23T14:11:09.578547-07:00","closed_at":"2025-12-23T14:11:09.578547-07:00"}
{"id":"hi_moe-joy","title":"TaskContext runtime state implementation","description":"Replace BeadsClient for runtime state with simple in-memory TaskContext object. Beads remains for project tracking, but runtime state uses a dict-based class with get/set/append. Upgrade to Redis/SQLite only if scaling problems arise.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-26T04:06:44.287845Z","closed_at":"2025-12-26T04:06:44.287845Z"}
{"id":"hi_moe-k1q","title":"Train initial LoRA adapters (python, math)","description":"Specs assume adapters exist but none are trained yet. Start with python-lora and math-lora using competitive programming data. Validates the specialist concept works.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T14:16:40.218737-07:00","updated_at":"2025-12-26T19:32:14.373872-08:00","closed_at":"2025-12-26T19:32:14.373872-08:00","close_reason":"Both python-lora and math-lora adapters trained and deployed. Server running with all 3 models: base, python-lora, math-lora","dependencies":[{"issue_id":"hi_moe-k1q","depends_on_id":"hi_moe-rj4","type":"blocks","created_at":"2025-12-26T03:38:12.826153Z","created_by":"claude"}]}
{"id":"hi_moe-kzt","title":"Introspective state object (extend Beads)","description":"Extend Beads to include system state - which LoRAs are loaded, Dispatcher routing accuracy, bottlenecks. Let Architect reason about system capabilities when planning.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:21:04.420281-07:00","updated_at":"2025-12-27T09:56:06.74309-08:00","closed_at":"2025-12-27T09:56:06.74309-08:00","close_reason":"Implemented IntrospectiveState in routines.py with specialist stats, bottlenecks, and prompt context generation","dependencies":[{"issue_id":"hi_moe-kzt","depends_on_id":"hi_moe-3ml","type":"blocks","created_at":"2025-12-23T13:23:40.27314-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-ld8","title":"Wire tiers together for integration","description":"Connect all four tiers (Architect → Dispatcher → Fleet → CodeRunner) with TaskContext state sharing. Blocking the stress test. Requires: finished LoRA training, defined OutcomeSchema.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-26T19:49:58.459933-08:00","closed_at":"2025-12-26T19:49:58.459933-08:00","close_reason":"Full tier stack wired: ProgressMonitor → Architect → Dispatcher → Fleet. CodeRunner integrated via Runner. Tests pass 2/2 with mock LLM.","dependencies":[{"issue_id":"hi_moe-ld8","depends_on_id":"hi_moe-k1q","type":"blocks","created_at":"2025-12-26T03:10:27.800072Z","created_by":"claude"},{"issue_id":"hi_moe-ld8","depends_on_id":"hi_moe-qwo","type":"blocks","created_at":"2025-12-26T03:10:27.800072Z","created_by":"claude"},{"issue_id":"hi_moe-ld8","depends_on_id":"hi_moe-4dy","type":"blocks","created_at":"2025-12-26T03:18:49.158216Z","created_by":"claude"},{"issue_id":"hi_moe-ld8","depends_on_id":"hi_moe-d87","type":"blocks","created_at":"2025-12-26T03:18:49.158216Z","created_by":"claude"}]}
{"id":"hi_moe-mut","title":"Competitive programming stress test","description":"First validation: competitive programming problems where coordination can be objectively measured. Proves tiers are actually coordinating effectively.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-23T13:22:46.463915-07:00","updated_at":"2025-12-26T03:10:27.800072Z","dependencies":[{"issue_id":"hi_moe-mut","depends_on_id":"hi_moe-q9q","type":"blocks","created_at":"2025-12-23T14:17:00.377654-07:00","created_by":"jinkang"},{"issue_id":"hi_moe-mut","depends_on_id":"hi_moe-3qj","type":"blocks","created_at":"2025-12-23T14:17:05.807672-07:00","created_by":"jinkang"},{"issue_id":"hi_moe-mut","depends_on_id":"hi_moe-r8q","type":"blocks","created_at":"2025-12-26T03:10:27.800072Z","created_by":"claude"}]}
{"id":"hi_moe-o46","title":"Credit assignment: identify failure source tier","description":"Open question: When tasks fail, how do you know which tier caused it? Need instrumentation and analysis approach to attribute failures to specific tiers for targeted improvement.","status":"closed","priority":3,"issue_type":"feature","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-27T09:50:25.132678-08:00","closed_at":"2025-12-27T09:50:25.132678-08:00","close_reason":"Implemented credit_assignment.py with tier instrumentation, failure attribution, and per-tier stats"}
{"id":"hi_moe-p6t","title":"Modal deployment for vLLM inference","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-23T19:44:30.215801-07:00","updated_at":"2025-12-23T19:45:32.427345-07:00","closed_at":"2025-12-23T19:45:32.427345-07:00"}
{"id":"hi_moe-q9q","title":"Routing Dispatcher tier implementation","description":"Second tier - breaks tasks into graphs and assigns to specialists. Hybrid routing: hardcoded rules for obvious mappings, learned Routing LoRA for ambiguous cases. Hardcoded successes bootstrap training data.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-23T13:22:22.168929-07:00","updated_at":"2025-12-23T14:33:09.824576-07:00","closed_at":"2025-12-23T14:33:09.824576-07:00"}
{"id":"hi_moe-qwo","title":"Define OutcomeSchema for Fleet→Architect handoff","description":"","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-23T20:32:34.131581-07:00","updated_at":"2025-12-26T19:41:54.360295-08:00","closed_at":"2025-12-26T19:41:54.360295-08:00","close_reason":"Added OutcomeSchema with FleetResult, DispatcherResult, ValidationSummary, and OutcomeEvaluation. Updated tiers.py to use structured types instead of dict.","dependencies":[{"issue_id":"hi_moe-qwo","depends_on_id":"hi_moe-k1q","type":"blocks","created_at":"2025-12-23T20:33:15.20357-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-r8q","title":"JSONL logging for training data collection","description":"Instrument all tiers now, train later. Log: Architect (goal, delegation, success criteria, revisions), Dispatcher (task, routing decision, rationale, specialist), Fleet (task, specialist, output, result), End-to-end (full trajectory, outcome, tokens, wall time). Format: JSONL append-only, one file per run, every entry has task_id.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-26T04:22:46.38629Z","closed_at":"2025-12-26T04:22:46.386304Z"}
{"id":"hi_moe-rj4","title":"Test base model without LoRAs first","description":"Validate if LoRA adapters are even needed. Run entire hierarchy with just base QwQ-32B + different prompts. Specialists would be prompt variations, not adapters. The test: if base model + prompts cannot pass competitive programming problems, adding LoRAs probably will not save you. If it can, architecture is validated without adapter complexity.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:37:53.239233Z","updated_at":"2025-12-26T16:07:27.386191-08:00","closed_at":"2025-12-26T16:07:27.386191-08:00","close_reason":"Base model passes 6/6 tests (100%). LoRA adapters not required for basic coding tasks. Architecture validated."}
{"id":"hi_moe-stl","title":"Add harder benchmarks to differentiate baseline vs hierarchy","description":"","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T07:55:24.280316-08:00","updated_at":"2025-12-27T08:27:59.539161-08:00","closed_at":"2025-12-27T08:27:59.539161-08:00","close_reason":"Added 3 medium-difficulty benchmark problems: Merge Intervals, Longest Palindromic Substring, Course Schedule. These include multi-step indicators to bypass fast path and test full tier hierarchy. Mock e2e confirms fast path works correctly (easy: 1 call, hard: 4 calls)."}
{"id":"hi_moe-vdx","title":"Train math specialist adapter on GSM8K dataset","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T15:36:50.830827-08:00","updated_at":"2025-12-26T19:28:32.83028-08:00","closed_at":"2025-12-26T19:28:32.83028-08:00","close_reason":"Math-lora adapter trained on 500 GSM8K examples. Evaluation shows 100% success rate on math problems. Adapter available at: math-lora"}
{"id":"hi_moe-vo8","title":"Collect trajectory data for online learning","description":"Use TrajectoryLogger to collect problem-solution pairs from successful executions. Feed this data back into training pipeline for continuous improvement.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T15:37:20.844173-08:00","updated_at":"2025-12-26T16:55:55.293987-08:00","closed_at":"2025-12-26T16:55:55.293987-08:00","close_reason":"Implemented TrajectoryDataCollector class that bridges trajectory logs to training format. Includes TrainingExample dataclass, collect_fleet_examples(), collect_dispatcher_examples(), write_training_file(), and convenience function collect_training_data(). 17 new tests added. All 128 tests pass."}
{"id":"hi_moe-wj4","title":"Incremental LoRA updates (online learning)","description":"Instead of discrete batch training, do online updates where successful executions slightly shift adapter weights. Research continual adapter learning approaches.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-23T13:21:45.368586-07:00","updated_at":"2025-12-23T13:21:45.368586-07:00","dependencies":[{"issue_id":"hi_moe-wj4","depends_on_id":"hi_moe-0n5","type":"blocks","created_at":"2025-12-23T13:24:03.547252-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-wvi","title":"v0.1 success criteria: end-to-end validation","description":"Run competitive programming problem through full stack: 1) Architect receives problem, 2) Architect delegates to Dispatcher, 3) Dispatcher routes to python specialist, 4) Specialist generates code, 5) CodeRunner executes/validates, 6) Outcome flows back via TaskContext, 7) Architect sees result. No smoothness, no self-reflection. Just: does the hierarchy coordinate?","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-27T05:42:26.2405-08:00","closed_at":"2025-12-27T05:42:26.2405-08:00","close_reason":"Full e2e validated with real vLLM endpoint (QwQ-32B-AWQ + python-lora). Two Sum problem: 4/4 test cases passed. Tier stack working: Architect→Dispatcher→Fleet→CodeRunner.","dependencies":[{"issue_id":"hi_moe-wvi","depends_on_id":"hi_moe-ld8","type":"blocks","created_at":"2025-12-26T03:10:27.800072Z","created_by":"claude"}]}
{"id":"hi_moe-x3j","title":"Add valence field to Beads state","description":"","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-23T20:32:27.003529-07:00","updated_at":"2025-12-23T20:32:27.003529-07:00","dependencies":[{"issue_id":"hi_moe-x3j","depends_on_id":"hi_moe-qwo","type":"blocks","created_at":"2025-12-23T20:33:08.65811-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-xv1","title":"Implement Runner control loop","description":"Python control loop on Modal that orchestrates all tiers. Responsibilities: 1) Receive problem, 2) Call Architect for goal/delegation, 3) Call Dispatcher for step sequence, 4) For each step call appropriate specialist, 5) Run CodeRunner if code generated, 6) Write outcomes to TaskContext, 7) Feed results back up the chain, 8) Handle retries and re-planning on failure.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-26T03:37:53.239233Z","updated_at":"2025-12-26T04:06:44.287845Z","closed_at":"2025-12-26T04:06:44.287845Z","dependencies":[{"issue_id":"hi_moe-xv1","depends_on_id":"hi_moe-4dy","type":"blocks","created_at":"2025-12-26T03:38:12.826153Z","created_by":"claude"},{"issue_id":"hi_moe-xv1","depends_on_id":"hi_moe-d87","type":"blocks","created_at":"2025-12-26T03:38:12.826153Z","created_by":"claude"}]}
{"id":"hi_moe-y97","title":"Confidence intervals \u0026 surprise detection","description":"Implement confidence bounds on expected outcomes. Flag surprising events (failures or successes outside bounds) for deeper analysis. Routine success gets compressed/forgotten.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-23T13:20:27.93588-07:00","updated_at":"2025-12-23T19:28:13.24612-07:00","closed_at":"2025-12-23T19:28:13.24612-07:00","dependencies":[{"issue_id":"hi_moe-y97","depends_on_id":"hi_moe-5o2","type":"blocks","created_at":"2025-12-23T13:23:22.026726-07:00","created_by":"jinkang"}]}
{"id":"hi_moe-z68","title":"State drift monitoring","description":"From Gemini feedback: State drift is a real risk. Monitor whether Architect knows what actually happened vs what it thinks happened. Track divergence between planned outcomes and actual execution results.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T03:09:55.446687Z","updated_at":"2025-12-27T09:50:25.079724-08:00","closed_at":"2025-12-27T09:50:25.079724-08:00","close_reason":"Implemented drift_monitor.py with plan/execution tracking, drift detection, and reporting","dependencies":[{"issue_id":"hi_moe-z68","depends_on_id":"hi_moe-ld8","type":"blocks","created_at":"2025-12-26T03:10:27.800072Z","created_by":"claude"}]}
