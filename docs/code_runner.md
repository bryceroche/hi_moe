# CodeRunner Specification

> Safe code execution sandbox for validating Fleet-generated solutions.

## Related Specifications

- **[Specialized Fleet](./specialized_fleet.md)**: Generates code artifacts that need execution
- **[Routing Dispatcher](./routing_dispatcher.md)**: Orchestrates code generation and testing subtasks
- **[Handoff Protocol](./handoff_protocol.md)**: Artifact types and outcome formats

## Required Imports

```python
from __future__ import annotations
import asyncio
import json
import os
import re
import tempfile
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

import docker
from docker.models.containers import Container

# From other specs
from handoff_protocol import Artifact
```

## Overview

The CodeRunner provides isolated code execution for validating solutions generated by the Specialized Fleet. It uses Docker containers to safely run untrusted code with strict resource limits.

```
Fleet generates code artifact
        │
        │ ExecutionRequest (code, language, test_cases)
        ▼
┌──────────────────────────────────────────────────────────────┐
│                       CODE RUNNER                             │
│                                                               │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐      │
│  │   Request   │───▶│   Docker    │───▶│   Result    │      │
│  │  Validator  │    │   Sandbox   │    │  Collector  │      │
│  └─────────────┘    └─────────────┘    └─────────────┘      │
│                            │                                  │
│                            ▼                                  │
│                   ┌─────────────────┐                        │
│                   │ Isolated Container │                      │
│                   │  • CPU limit      │                       │
│                   │  • Memory limit   │                       │
│                   │  • Network: none  │                       │
│                   │  • Timeout        │                       │
│                   └─────────────────┘                        │
└──────────────────────────────────────────────────────────────┘
        │
        │ ExecutionResult (passed, failed, errors, stdout)
        ▼
Dispatcher aggregates results
```

## CodeRunner Interface

### Execution Request

```python
@dataclass
class ExecutionRequest:
    """Request to execute code."""
    request_id: str                     # Unique identifier
    code: str                           # Code to execute
    language: Language                  # Programming language
    test_cases: list[TestCase]          # Test cases to run
    timeout_ms: int                     # Per-test timeout
    total_timeout_ms: int               # Total execution timeout
    memory_limit_mb: int = 256          # Memory limit per container
    cpu_limit: float = 1.0              # CPU cores limit
    metadata: dict[str, Any] = field(default_factory=dict)

class Language(Enum):
    PYTHON = "python"
    PYTHON3 = "python3"
    CPP = "cpp"
    C = "c"
    JAVA = "java"
    JAVASCRIPT = "javascript"
    GO = "go"
    RUST = "rust"

@dataclass
class TestCase:
    """A single test case."""
    id: str
    input: str                          # stdin input
    expected_output: str                # Expected stdout
    is_hidden: bool = False             # Hidden test (for validation)
    timeout_ms: int | None = None       # Override per-test timeout
    description: str = ""               # Human-readable description
```

### Execution Result

```python
@dataclass
class ExecutionResult:
    """Result of code execution."""
    request_id: str
    status: ExecutionStatus
    test_results: list[TestResult]
    total_time_ms: int
    compilation_output: str | None      # For compiled languages
    summary: str                        # Human-readable summary
    error_info: ExecutionError | None

class ExecutionStatus(Enum):
    ALL_PASSED = "all_passed"           # All test cases passed
    SOME_PASSED = "some_passed"         # Partial success
    ALL_FAILED = "all_failed"           # No test cases passed
    COMPILATION_ERROR = "compilation_error"
    RUNTIME_ERROR = "runtime_error"
    TIMEOUT = "timeout"
    MEMORY_EXCEEDED = "memory_exceeded"
    SANDBOX_ERROR = "sandbox_error"     # Docker/infrastructure issue

@dataclass
class TestResult:
    """Result of a single test case."""
    test_id: str
    status: TestStatus
    actual_output: str
    expected_output: str
    execution_time_ms: int
    memory_used_kb: int
    error_message: str | None = None

class TestStatus(Enum):
    PASSED = "passed"
    WRONG_ANSWER = "wrong_answer"
    RUNTIME_ERROR = "runtime_error"
    TIMEOUT = "timeout"
    MEMORY_EXCEEDED = "memory_exceeded"

@dataclass
class ExecutionError:
    """Detailed error information."""
    code: str                           # Error code
    message: str                        # Error message
    stage: str                          # "compilation", "execution", "validation"
    details: str | None = None          # Stack trace or additional info
```

## Docker Sandbox

### Container Configuration

```python
# Default Docker images for each language
DEFAULT_IMAGES: dict[Language, str] = {
    Language.PYTHON: "python:3.11-slim",
    Language.PYTHON3: "python:3.11-slim",
    Language.CPP: "gcc:12",
    Language.C: "gcc:12",
    Language.JAVA: "openjdk:17-slim",
    Language.JAVASCRIPT: "node:20-slim",
    Language.GO: "golang:1.21-alpine",
    Language.RUST: "rust:1.74-slim",
}

LANGUAGE_EXTENSIONS: dict[Language, str] = {
    Language.PYTHON: "py",
    Language.PYTHON3: "py",
    Language.CPP: "cpp",
    Language.C: "c",
    Language.JAVA: "java",
    Language.JAVASCRIPT: "js",
    Language.GO: "go",
    Language.RUST: "rs",
}

COMPILED_LANGUAGES = {Language.CPP, Language.C, Language.JAVA, Language.GO, Language.RUST}

# Execution commands per language
# Note: Java uses {classname} placeholder, resolved at runtime
EXECUTION_COMMANDS: dict[Language, list[str]] = {
    Language.PYTHON: ["python", "solution.py"],
    Language.PYTHON3: ["python3", "solution.py"],
    Language.CPP: ["./solution"],
    Language.C: ["./solution"],
    Language.JAVA: ["java", "{classname}"],  # Placeholder, resolved in get_execution_command
    Language.JAVASCRIPT: ["node", "solution.js"],
    Language.GO: ["./solution"],
    Language.RUST: ["./solution"],
}

def get_execution_command(language: Language, code: str) -> list[str]:
    """Get execution command, resolving any placeholders."""
    command = EXECUTION_COMMANDS[language].copy()

    if language == Language.JAVA:
        # Extract class name from code
        match = re.search(r"public\s+class\s+(\w+)", code)
        classname = match.group(1) if match else "Solution"
        command = [c.replace("{classname}", classname) for c in command]

    return command

# Compilation commands per language
COMPILATION_COMMANDS: dict[Language, list[str]] = {
    Language.CPP: ["g++", "-O2", "-std=c++17", "-o", "solution", "solution.cpp"],
    Language.C: ["gcc", "-O2", "-std=c11", "-o", "solution", "solution.c"],
    Language.JAVA: ["javac", "solution.java"],
    Language.GO: ["go", "build", "-o", "solution", "solution.go"],
    Language.RUST: ["rustc", "-O", "-o", "solution", "solution.rs"],
}
```

### Container Execution

```python
class ContainerRunner:
    """Runs code in isolated Docker containers."""

    def __init__(
        self,
        docker_client: docker.DockerClient,
        default_memory_mb: int = 256,
        default_cpu: float = 1.0,
    ):
        self.client = docker_client
        self.default_memory_mb = default_memory_mb
        self.default_cpu = default_cpu

    async def run(
        self,
        image: str,
        command: list[str],
        workspace: Path,
        stdin_data: str,
        timeout_ms: int,
        memory_limit_mb: int,
        cpu_limit: float,
    ) -> ContainerResult:
        """Run command in container with resource limits."""
        container: Container | None = None
        start_time = time.monotonic()

        try:
            # Create container with strict isolation
            container = self.client.containers.create(
                image=image,
                command=command,
                working_dir="/workspace",
                volumes={
                    str(workspace): {"bind": "/workspace", "mode": "ro"}
                },
                mem_limit=f"{memory_limit_mb}m",
                memswap_limit=f"{memory_limit_mb}m",  # No swap
                cpu_period=100000,
                cpu_quota=int(100000 * cpu_limit),
                network_disabled=True,              # No network access
                read_only=True,                     # Read-only root filesystem
                security_opt=["no-new-privileges"], # No privilege escalation
                cap_drop=["ALL"],                   # Drop all capabilities
                pids_limit=64,                      # Limit processes
                stdin_open=True,
                detach=True,
            )

            # Start container
            container.start()

            # Send stdin data
            socket = container.attach_socket(params={"stdin": 1, "stream": 1})
            socket._sock.sendall(stdin_data.encode())
            socket._sock.shutdown(2)  # Close stdin

            # Wait for completion with timeout
            timeout_sec = timeout_ms / 1000
            exit_code = await asyncio.wait_for(
                asyncio.to_thread(container.wait, timeout=timeout_sec),
                timeout=timeout_sec + 1  # Extra buffer for wait_for
            )

            # Get output
            stdout = container.logs(stdout=True, stderr=False).decode()
            stderr = container.logs(stdout=False, stderr=True).decode()

            execution_time_ms = int((time.monotonic() - start_time) * 1000)

            # Get memory stats if available
            try:
                stats = container.stats(stream=False)
                memory_used_kb = stats.get("memory_stats", {}).get("usage", 0) // 1024
            except Exception:
                memory_used_kb = 0

            return ContainerResult(
                exit_code=exit_code["StatusCode"],
                stdout=stdout,
                stderr=stderr,
                execution_time_ms=execution_time_ms,
                memory_used_kb=memory_used_kb,
                timed_out=False,
                memory_exceeded=False,
            )

        except asyncio.TimeoutError:
            execution_time_ms = int((time.monotonic() - start_time) * 1000)
            return ContainerResult(
                exit_code=-1,
                stdout="",
                stderr="Execution timed out",
                execution_time_ms=execution_time_ms,
                memory_used_kb=0,
                timed_out=True,
                memory_exceeded=False,
            )

        except docker.errors.ContainerError as e:
            execution_time_ms = int((time.monotonic() - start_time) * 1000)
            # Check if OOM killed
            if container and container.attrs.get("State", {}).get("OOMKilled"):
                return ContainerResult(
                    exit_code=-1,
                    stdout="",
                    stderr="Memory limit exceeded",
                    execution_time_ms=execution_time_ms,
                    memory_used_kb=memory_limit_mb * 1024,
                    timed_out=False,
                    memory_exceeded=True,
                )
            raise

        finally:
            if container:
                try:
                    container.remove(force=True)
                except Exception:
                    pass  # Best effort cleanup

@dataclass
class ContainerResult:
    """Result from container execution."""
    exit_code: int
    stdout: str
    stderr: str
    execution_time_ms: int
    memory_used_kb: int
    timed_out: bool
    memory_exceeded: bool
```

## Test Execution

### Test Runner

```python
class TestRunner:
    """Runs test cases against code."""

    def __init__(self, container_runner: ContainerRunner):
        self.runner = container_runner

    async def run_tests(
        self,
        image: str,
        command: list[str],
        workspace: Path,
        test_cases: list[TestCase],
        default_timeout_ms: int,
        memory_limit_mb: int,
        cpu_limit: float,
        total_timeout_ms: int,
    ) -> list[TestResult]:
        """Run all test cases with total timeout."""
        results: list[TestResult] = []
        start_time = time.monotonic()

        for test_case in test_cases:
            # Check total timeout
            elapsed_ms = int((time.monotonic() - start_time) * 1000)
            if elapsed_ms >= total_timeout_ms:
                # Mark remaining tests as timed out
                results.append(TestResult(
                    test_id=test_case.id,
                    status=TestStatus.TIMEOUT,
                    actual_output="",
                    expected_output=test_case.expected_output,
                    execution_time_ms=0,
                    memory_used_kb=0,
                    error_message="Total timeout exceeded",
                ))
                continue

            # Run single test
            test_timeout = test_case.timeout_ms or default_timeout_ms
            remaining = total_timeout_ms - elapsed_ms
            effective_timeout = min(test_timeout, remaining)

            result = await self._run_single_test(
                image=image,
                command=command,
                workspace=workspace,
                test_case=test_case,
                timeout_ms=effective_timeout,
                memory_limit_mb=memory_limit_mb,
                cpu_limit=cpu_limit,
            )
            results.append(result)

        return results

    async def _run_single_test(
        self,
        image: str,
        command: list[str],
        workspace: Path,
        test_case: TestCase,
        timeout_ms: int,
        memory_limit_mb: int,
        cpu_limit: float,
    ) -> TestResult:
        """Run a single test case."""
        container_result = await self.runner.run(
            image=image,
            command=command,
            workspace=workspace,
            stdin_data=test_case.input,
            timeout_ms=timeout_ms,
            memory_limit_mb=memory_limit_mb,
            cpu_limit=cpu_limit,
        )

        # Determine status
        if container_result.timed_out:
            status = TestStatus.TIMEOUT
            error_message = "Test execution timed out"
        elif container_result.memory_exceeded:
            status = TestStatus.MEMORY_EXCEEDED
            error_message = "Memory limit exceeded"
        elif container_result.exit_code != 0:
            status = TestStatus.RUNTIME_ERROR
            error_message = container_result.stderr.strip() or f"Exit code: {container_result.exit_code}"
        else:
            # Compare output
            actual = self._normalize_output(container_result.stdout)
            expected = self._normalize_output(test_case.expected_output)
            if actual == expected:
                status = TestStatus.PASSED
                error_message = None
            else:
                status = TestStatus.WRONG_ANSWER
                error_message = None

        return TestResult(
            test_id=test_case.id,
            status=status,
            actual_output=container_result.stdout,
            expected_output=test_case.expected_output,
            execution_time_ms=container_result.execution_time_ms,
            memory_used_kb=container_result.memory_used_kb,
            error_message=error_message,
        )

    def _normalize_output(self, output: str) -> str:
        """Normalize output for comparison."""
        # Strip trailing whitespace from each line
        lines = [line.rstrip() for line in output.splitlines()]
        # Remove trailing empty lines
        while lines and not lines[-1]:
            lines.pop()
        return "\n".join(lines)
```

### Compilation

```python
class Compiler:
    """Compiles code for compiled languages."""

    def __init__(self, container_runner: ContainerRunner):
        self.runner = container_runner

    async def compile(
        self,
        image: str,
        workspace: Path,
        language: Language,
        timeout_ms: int = 30000,
        memory_limit_mb: int = 512,
    ) -> CompilationResult:
        """Compile code in container."""
        command = COMPILATION_COMMANDS.get(language)
        if not command:
            return CompilationResult(
                success=True,
                output="",
                error=None,
            )

        # Compilation needs write access to workspace
        container_result = await self._run_compilation(
            image=image,
            command=command,
            workspace=workspace,
            timeout_ms=timeout_ms,
            memory_limit_mb=memory_limit_mb,
        )

        if container_result.timed_out:
            return CompilationResult(
                success=False,
                output="",
                error="Compilation timed out",
            )

        if container_result.exit_code != 0:
            return CompilationResult(
                success=False,
                output=container_result.stdout,
                error=container_result.stderr or "Compilation failed",
            )

        return CompilationResult(
            success=True,
            output=container_result.stdout,
            error=None,
        )

    async def _run_compilation(
        self,
        image: str,
        command: list[str],
        workspace: Path,
        timeout_ms: int,
        memory_limit_mb: int,
    ) -> ContainerResult:
        """Run compilation with write access."""
        # For compilation, we need write access to create binary
        container = self.runner.client.containers.create(
            image=image,
            command=command,
            working_dir="/workspace",
            volumes={
                str(workspace): {"bind": "/workspace", "mode": "rw"}  # Write access
            },
            mem_limit=f"{memory_limit_mb}m",
            network_disabled=True,
            security_opt=["no-new-privileges"],
            pids_limit=64,
            detach=True,
        )

        try:
            container.start()
            exit_result = container.wait(timeout=timeout_ms / 1000)

            stdout = container.logs(stdout=True, stderr=False).decode()
            stderr = container.logs(stdout=False, stderr=True).decode()

            return ContainerResult(
                exit_code=exit_result["StatusCode"],
                stdout=stdout,
                stderr=stderr,
                execution_time_ms=0,  # Not tracked for compilation
                memory_used_kb=0,
                timed_out=False,
                memory_exceeded=False,
            )
        except Exception as e:
            return ContainerResult(
                exit_code=-1,
                stdout="",
                stderr=str(e),
                execution_time_ms=0,
                memory_used_kb=0,
                timed_out=True,
                memory_exceeded=False,
            )
        finally:
            try:
                container.remove(force=True)
            except Exception:
                pass

@dataclass
class CompilationResult:
    """Result of compilation."""
    success: bool
    output: str
    error: str | None
```

## Main CodeRunner Class

```python
class CodeRunner:
    """Main entry point for code execution."""

    def __init__(
        self,
        docker_client: docker.DockerClient | None = None,
        images: dict[Language, str] | None = None,
    ):
        self.client = docker_client or docker.from_env()
        self.images = images or DEFAULT_IMAGES
        self.container_runner = ContainerRunner(self.client)
        self.test_runner = TestRunner(self.container_runner)
        self.compiler = Compiler(self.container_runner)

    async def execute(self, request: ExecutionRequest) -> ExecutionResult:
        """Execute code and run test cases."""
        start_time = time.monotonic()

        # Validate request
        try:
            self._validate_request(request)
        except ValueError as e:
            return self._validation_error_result(request, str(e), start_time)

        # Get image
        image = self.images.get(request.language)
        if not image:
            return self._unsupported_language_result(request, start_time)

        # Sanitize code (defense in depth - Docker is primary isolation)
        sanitized_code = sanitize_code(request.code, request.language)

        # Create workspace
        with tempfile.TemporaryDirectory() as workspace:
            workspace_path = Path(workspace)

            # Write sanitized code
            sanitized_request = ExecutionRequest(
                request_id=request.request_id,
                code=sanitized_code,
                language=request.language,
                test_cases=request.test_cases,
                timeout_ms=request.timeout_ms,
                total_timeout_ms=request.total_timeout_ms,
                memory_limit_mb=request.memory_limit_mb,
                cpu_limit=request.cpu_limit,
                metadata=request.metadata,
            )
            code_file = self._write_code(workspace_path, sanitized_request)

            # Compile if needed
            if request.language in COMPILED_LANGUAGES:
                compile_result = await self.compiler.compile(
                    image=image,
                    workspace=workspace_path,
                    language=request.language,
                    timeout_ms=30000,  # 30s compile timeout
                    memory_limit_mb=512,
                )

                if not compile_result.success:
                    return ExecutionResult(
                        request_id=request.request_id,
                        status=ExecutionStatus.COMPILATION_ERROR,
                        test_results=[],
                        total_time_ms=int((time.monotonic() - start_time) * 1000),
                        compilation_output=compile_result.error,
                        summary=f"Compilation failed: {compile_result.error}",
                        error_info=ExecutionError(
                            code="COMPILATION_ERROR",
                            message=compile_result.error or "Compilation failed",
                            stage="compilation",
                            details=compile_result.output,
                        ),
                    )

            # Run tests
            command = get_execution_command(request.language, sanitized_code)
            test_results = await self.test_runner.run_tests(
                image=image,
                command=command,
                workspace=workspace_path,
                test_cases=request.test_cases,
                default_timeout_ms=request.timeout_ms,
                memory_limit_mb=request.memory_limit_mb,
                cpu_limit=request.cpu_limit,
                total_timeout_ms=request.total_timeout_ms,
            )

        total_time_ms = int((time.monotonic() - start_time) * 1000)
        return self._build_result(request, test_results, total_time_ms)

    def _validate_request(self, request: ExecutionRequest) -> None:
        """Validate execution request."""
        if not request.code.strip():
            raise ValueError("Empty code")
        if not request.test_cases:
            raise ValueError("No test cases provided")
        if request.memory_limit_mb < 16 or request.memory_limit_mb > 1024:
            raise ValueError(f"Invalid memory limit: {request.memory_limit_mb}MB")
        if request.timeout_ms < 100 or request.timeout_ms > 60000:
            raise ValueError(f"Invalid timeout: {request.timeout_ms}ms")

    def _write_code(self, workspace: Path, request: ExecutionRequest) -> Path:
        """Write code to workspace."""
        extension = LANGUAGE_EXTENSIONS[request.language]

        # Java requires specific filename matching class name
        if request.language == Language.JAVA:
            match = re.search(r"public\s+class\s+(\w+)", request.code)
            filename = f"{match.group(1)}.java" if match else "Solution.java"
        else:
            filename = f"solution.{extension}"

        code_file = workspace / filename
        code_file.write_text(request.code)
        return code_file

    def _build_result(
        self,
        request: ExecutionRequest,
        test_results: list[TestResult],
        total_time_ms: int,
    ) -> ExecutionResult:
        """Build execution result from test results."""
        passed = sum(1 for r in test_results if r.status == TestStatus.PASSED)
        total = len(test_results)

        # Handle empty results (shouldn't happen, but defensive)
        if total == 0:
            return ExecutionResult(
                request_id=request.request_id,
                status=ExecutionStatus.SANDBOX_ERROR,
                test_results=[],
                total_time_ms=total_time_ms,
                compilation_output=None,
                summary="No test cases were executed",
                error_info=ExecutionError(
                    code="NO_TESTS",
                    message="No test results produced",
                    stage="execution",
                ),
            )

        # Determine overall status
        if passed == total:
            status = ExecutionStatus.ALL_PASSED
        elif passed > 0:
            status = ExecutionStatus.SOME_PASSED
        elif any(r.status == TestStatus.TIMEOUT for r in test_results):
            status = ExecutionStatus.TIMEOUT
        elif any(r.status == TestStatus.MEMORY_EXCEEDED for r in test_results):
            status = ExecutionStatus.MEMORY_EXCEEDED
        elif any(r.status == TestStatus.RUNTIME_ERROR for r in test_results):
            status = ExecutionStatus.RUNTIME_ERROR
        else:
            status = ExecutionStatus.ALL_FAILED

        # Build summary
        summary = f"{passed}/{total} test cases passed"
        if status == ExecutionStatus.ALL_PASSED:
            summary = f"All {total} test cases passed"
        elif status == ExecutionStatus.RUNTIME_ERROR:
            error_test = next(r for r in test_results if r.status == TestStatus.RUNTIME_ERROR)
            summary = f"{passed}/{total} passed. Runtime error: {error_test.error_message}"

        # Build error info for failures
        error_info = None
        if status not in (ExecutionStatus.ALL_PASSED, ExecutionStatus.SOME_PASSED):
            failed_test = next(
                (r for r in test_results if r.status != TestStatus.PASSED),
                None
            )
            if failed_test:
                error_info = ExecutionError(
                    code=failed_test.status.value.upper(),
                    message=failed_test.error_message or f"Test {failed_test.test_id} failed",
                    stage="execution",
                    details=failed_test.actual_output[:500] if failed_test.actual_output else None,
                )

        return ExecutionResult(
            request_id=request.request_id,
            status=status,
            test_results=test_results,
            total_time_ms=total_time_ms,
            compilation_output=None,
            summary=summary,
            error_info=error_info,
        )

    def _validation_error_result(
        self,
        request: ExecutionRequest,
        error: str,
        start_time: float,
    ) -> ExecutionResult:
        """Build result for validation errors."""
        return ExecutionResult(
            request_id=request.request_id,
            status=ExecutionStatus.SANDBOX_ERROR,
            test_results=[],
            total_time_ms=int((time.monotonic() - start_time) * 1000),
            compilation_output=None,
            summary=f"Validation error: {error}",
            error_info=ExecutionError(
                code="VALIDATION_ERROR",
                message=error,
                stage="validation",
            ),
        )

    def _unsupported_language_result(
        self,
        request: ExecutionRequest,
        start_time: float,
    ) -> ExecutionResult:
        """Build result for unsupported language."""
        return ExecutionResult(
            request_id=request.request_id,
            status=ExecutionStatus.SANDBOX_ERROR,
            test_results=[],
            total_time_ms=int((time.monotonic() - start_time) * 1000),
            compilation_output=None,
            summary=f"Unsupported language: {request.language}",
            error_info=ExecutionError(
                code="UNSUPPORTED_LANGUAGE",
                message=f"Language {request.language} is not supported",
                stage="validation",
            ),
        )
```

## Fleet Integration

### Converting Fleet Artifacts to Execution Requests

```python
def artifact_to_execution_request(
    artifact: Artifact,
    test_cases: list[dict],
    request_id: str | None = None,
    timeout_ms: int = 5000,
    total_timeout_ms: int = 60000,
) -> ExecutionRequest:
    """Convert Fleet code artifact to execution request."""
    # Extract code from artifact
    code = artifact.inline_content
    if not code and artifact.content_ref:
        # Would need to fetch from Beads
        raise ValueError("Large artifacts must be resolved before execution")

    # Detect language from metadata
    language_str = artifact.metadata.get("language", "python")
    try:
        language = Language(language_str.lower())
    except ValueError:
        language = Language.PYTHON  # Default

    # Convert test cases
    converted_tests = [
        TestCase(
            id=tc.get("id", f"test_{i}"),
            input=tc.get("input", ""),
            expected_output=tc.get("expected", tc.get("expected_output", "")),
            is_hidden=tc.get("hidden", False),
            description=tc.get("description", ""),
        )
        for i, tc in enumerate(test_cases)
    ]

    return ExecutionRequest(
        request_id=request_id or str(uuid.uuid4()),
        code=code,
        language=language,
        test_cases=converted_tests,
        timeout_ms=timeout_ms,
        total_timeout_ms=total_timeout_ms,
    )


def execution_result_to_artifact(
    result: ExecutionResult,
    beads_key: str | None = None,
) -> tuple[Artifact, str | None]:
    """
    Convert execution result to Fleet artifact.

    Returns (artifact, large_content) tuple.
    If content > 1KB, large_content contains the full JSON to store in Beads.
    """
    passed = sum(1 for r in result.test_results if r.status == TestStatus.PASSED)
    total = len(result.test_results)

    # Build full content
    content = json.dumps({
        "status": result.status.value,
        "passed": passed,
        "total": total,
        "total_time_ms": result.total_time_ms,
        "summary": result.summary,
        "test_results": [
            {
                "id": r.test_id,
                "status": r.status.value,
                "time_ms": r.execution_time_ms,
                "memory_kb": r.memory_used_kb,
            }
            for r in result.test_results
        ],
    }, indent=2)

    # Determine inline vs reference based on size
    if len(content) < 1024:
        return Artifact(
            artifact_type="test_result",
            content_ref=None,
            inline_content=content,
            metadata={
                "status": result.status.value,
                "passed": passed,
                "total": total,
            },
        ), None
    else:
        # Large result - return content for Beads storage
        content_ref = beads_key or f"execution/results/{result.request_id}"
        return Artifact(
            artifact_type="test_result",
            content_ref=f"beads:{content_ref}",
            inline_content=None,
            metadata={
                "status": result.status.value,
                "passed": passed,
                "total": total,
            },
        ), content
```

## Security Considerations

### Container Isolation

```python
SECURITY_CONFIG = {
    # Network isolation
    "network_disabled": True,

    # Filesystem restrictions
    "read_only": True,           # Read-only root filesystem
    "volumes": "ro",             # Read-only volume mounts (except compilation)

    # Privilege restrictions
    "security_opt": ["no-new-privileges"],
    "cap_drop": ["ALL"],         # Drop all capabilities

    # Resource limits
    "pids_limit": 64,            # Max 64 processes
    "mem_limit": "256m",         # Default memory limit
    "memswap_limit": "256m",     # No swap
    "cpu_period": 100000,
    "cpu_quota": 100000,         # 1 CPU core

    # Timeout enforcement
    "timeout_ms": 5000,          # Default per-test timeout
    "total_timeout_ms": 60000,   # Total execution timeout
}
```

### Input Sanitization

```python
def sanitize_code(code: str, language: Language) -> str:
    """Sanitize code to prevent sandbox escapes."""
    # Remove null bytes
    code = code.replace("\x00", "")

    # Language-specific checks
    if language in (Language.PYTHON, Language.PYTHON3):
        # Block dangerous imports
        dangerous_patterns = [
            r"import\s+os",
            r"import\s+subprocess",
            r"import\s+socket",
            r"from\s+os\s+import",
            r"__import__\s*\(",
            r"eval\s*\(",
            r"exec\s*\(",
            r"open\s*\([^)]*['\"][wa]",  # Writing to files
        ]
        # Note: These are logged but not blocked - Docker isolation is primary defense

    return code
```

## Configuration

```yaml
# coderunner_config.yaml
docker:
  default_image_prefix: "coderunner"
  pull_policy: "if_not_present"  # "always", "if_not_present", "never"

limits:
  memory_mb: 256
  cpu_cores: 1.0
  per_test_timeout_ms: 5000
  total_timeout_ms: 60000
  max_output_size_kb: 64
  max_processes: 64

languages:
  python:
    image: "python:3.11-slim"
    extension: "py"
    compile: false
  cpp:
    image: "gcc:12"
    extension: "cpp"
    compile: true
    compile_command: ["g++", "-O2", "-std=c++17", "-o", "solution", "solution.cpp"]

security:
  network_disabled: true
  read_only_root: true
  no_new_privileges: true
  cap_drop_all: true
```

## Usage Example

```python
async def main():
    # Create runner
    runner = CodeRunner()

    # Define request
    request = ExecutionRequest(
        request_id="test-001",
        code="""
def two_sum(nums, target):
    seen = {}
    for i, num in enumerate(nums):
        complement = target - num
        if complement in seen:
            return [seen[complement], i]
        seen[num] = i
    return []

# Read input
nums = list(map(int, input().split()))
target = int(input())
result = two_sum(nums, target)
print(" ".join(map(str, result)))
""",
        language=Language.PYTHON,
        test_cases=[
            TestCase(
                id="test_1",
                input="2 7 11 15\n9",
                expected_output="0 1",
            ),
            TestCase(
                id="test_2",
                input="3 2 4\n6",
                expected_output="1 2",
            ),
            TestCase(
                id="test_3",
                input="3 3\n6",
                expected_output="0 1",
            ),
        ],
        timeout_ms=5000,
        total_timeout_ms=30000,
    )

    # Execute
    result = await runner.execute(request)

    print(f"Status: {result.status.value}")
    print(f"Summary: {result.summary}")
    for test in result.test_results:
        print(f"  {test.test_id}: {test.status.value} ({test.execution_time_ms}ms)")
```

## Testing Strategy

### Unit Tests

```python
@pytest.mark.asyncio
async def test_simple_python_execution():
    runner = CodeRunner()
    request = ExecutionRequest(
        request_id="unit-1",
        code="print(int(input()) * 2)",
        language=Language.PYTHON,
        test_cases=[
            TestCase(id="t1", input="5", expected_output="10"),
            TestCase(id="t2", input="0", expected_output="0"),
        ],
        timeout_ms=5000,
        total_timeout_ms=30000,
    )

    result = await runner.execute(request)

    assert result.status == ExecutionStatus.ALL_PASSED
    assert len(result.test_results) == 2
    assert all(r.status == TestStatus.PASSED for r in result.test_results)

@pytest.mark.asyncio
async def test_timeout_handling():
    runner = CodeRunner()
    request = ExecutionRequest(
        request_id="timeout-1",
        code="import time; time.sleep(10); print('done')",
        language=Language.PYTHON,
        test_cases=[TestCase(id="t1", input="", expected_output="done")],
        timeout_ms=1000,  # 1 second timeout
        total_timeout_ms=5000,
    )

    result = await runner.execute(request)

    assert result.status == ExecutionStatus.TIMEOUT

@pytest.mark.asyncio
async def test_runtime_error():
    runner = CodeRunner()
    request = ExecutionRequest(
        request_id="error-1",
        code="x = 1/0",
        language=Language.PYTHON,
        test_cases=[TestCase(id="t1", input="", expected_output="")],
        timeout_ms=5000,
        total_timeout_ms=30000,
    )

    result = await runner.execute(request)

    assert result.status == ExecutionStatus.RUNTIME_ERROR

@pytest.mark.asyncio
async def test_cpp_compilation():
    runner = CodeRunner()
    request = ExecutionRequest(
        request_id="cpp-1",
        code="""
#include <iostream>
int main() {
    int x;
    std::cin >> x;
    std::cout << x * 2 << std::endl;
    return 0;
}
""",
        language=Language.CPP,
        test_cases=[TestCase(id="t1", input="5", expected_output="10")],
        timeout_ms=5000,
        total_timeout_ms=30000,
    )

    result = await runner.execute(request)

    assert result.status == ExecutionStatus.ALL_PASSED
```

### Integration Tests

```python
@pytest.mark.integration
async def test_fleet_integration():
    """Test full flow from Fleet artifact to execution."""
    # Simulate Fleet artifact
    artifact = Artifact(
        artifact_type="code",
        content_ref=None,
        inline_content="print(sum(map(int, input().split())))",
        metadata={"language": "python"},
    )

    test_cases = [
        {"id": "t1", "input": "1 2 3", "expected": "6"},
        {"id": "t2", "input": "10 20", "expected": "30"},
    ]

    # Convert and execute
    request = artifact_to_execution_request(artifact, test_cases)
    runner = CodeRunner()
    result = await runner.execute(request)

    # Convert result back to artifact
    result_artifact, large_content = execution_result_to_artifact(result)

    assert result.status == ExecutionStatus.ALL_PASSED
    assert result_artifact.artifact_type == "test_result"
    assert result_artifact.metadata["passed"] == 2
    assert large_content is None  # Small result, should be inline
```
